{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Tia3MP1SJpgj"
   },
   "source": [
    "# Springboard Data Science Career Track Unit 4 Challenge - Tier 3 Complete\n",
    "\n",
    "## Objectives\n",
    "Hey! Great job getting through those challenging DataCamp courses. You're learning a lot in a short span of time. \n",
    "\n",
    "In this notebook, you're going to apply the skills you've been learning, bridging the gap between the controlled environment of DataCamp and the *slightly* messier work that data scientists do with actual datasets!\n",
    "\n",
    "Here’s the mystery we’re going to solve: ***which boroughs of London have seen the greatest increase in housing prices, on average, over the last two decades?***\n",
    "\n",
    "\n",
    "A borough is just a fancy word for district. You may be familiar with the five boroughs of New York… well, there are 32 boroughs within Greater London [(here's some info for the curious)](https://en.wikipedia.org/wiki/London_boroughs). Some of them are more desirable areas to live in, and the data will reflect that with a greater rise in housing prices.\n",
    "\n",
    "***This is the Tier 3 notebook, which means it's not filled in at all: we'll just give you the skeleton of a project, the brief and the data. It's up to you to play around with it and see what you can find out! Good luck! If you struggle, feel free to look at easier tiers for help; but try to dip in and out of them, as the more independent work you do, the better it is for your learning!***\n",
    "\n",
    "This challenge will make use of only what you learned in the following DataCamp courses: \n",
    "- Prework courses (Introduction to Python for Data Science, Intermediate Python for Data Science)\n",
    "- Data Types for Data Science\n",
    "- Python Data Science Toolbox (Part One) \n",
    "- pandas Foundations\n",
    "- Manipulating DataFrames with pandas\n",
    "- Merging DataFrames with pandas\n",
    "\n",
    "Of the tools, techniques and concepts in the above DataCamp courses, this challenge should require the application of the following: \n",
    "- **pandas**\n",
    "    - **data ingestion and inspection** (pandas Foundations, Module One) \n",
    "    - **exploratory data analysis** (pandas Foundations, Module Two)\n",
    "    - **tidying and cleaning** (Manipulating DataFrames with pandas, Module Three) \n",
    "    - **transforming DataFrames** (Manipulating DataFrames with pandas, Module One)\n",
    "    - **subsetting DataFrames with lists** (Manipulating DataFrames with pandas, Module One) \n",
    "    - **filtering DataFrames** (Manipulating DataFrames with pandas, Module One) \n",
    "    - **grouping data** (Manipulating DataFrames with pandas, Module Four) \n",
    "    - **melting data** (Manipulating DataFrames with pandas, Module Three) \n",
    "    - **advanced indexing** (Manipulating DataFrames with pandas, Module Four) \n",
    "- **matplotlib** (Intermediate Python for Data Science, Module One)\n",
    "- **fundamental data types** (Data Types for Data Science, Module One) \n",
    "- **dictionaries** (Intermediate Python for Data Science, Module Two)\n",
    "- **handling dates and times** (Data Types for Data Science, Module Four)\n",
    "- **function definition** (Python Data Science Toolbox - Part One, Module One)\n",
    "- **default arguments, variable length, and scope** (Python Data Science Toolbox - Part One, Module Two) \n",
    "- **lambda functions and error handling** (Python Data Science Toolbox - Part One, Module Four) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ipgd2nV8Jpgl"
   },
   "source": [
    "## The Data Science Pipeline\n",
    "\n",
    "This is Tier Three, so we'll get you started. But after that, it's all in your hands! When you feel done with your investigations, look back over what you've accomplished, and prepare a quick presentation of your findings for the next mentor meeting. \n",
    "\n",
    "Data Science is magical. In this case study, you'll get to apply some complex machine learning algorithms. But as  [David Spiegelhalter](https://www.youtube.com/watch?v=oUs1uvsz0Ok) reminds us, there is no substitute for simply **taking a really, really good look at the data.** Sometimes, this is all we need to answer our question.\n",
    "\n",
    "Data Science projects generally adhere to the four stages of Data Science Pipeline:\n",
    "1. Sourcing and loading \n",
    "2. Cleaning, transforming, and visualizing \n",
    "3. Modeling \n",
    "4. Evaluating and concluding \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zswDqbefJpgm"
   },
   "source": [
    "### 1. Sourcing and Loading \n",
    "\n",
    "Any Data Science project kicks off by importing  ***pandas***. The documentation of this wonderful library can be found [here](https://pandas.pydata.org/). As you've seen, pandas is conveniently connected to the [Numpy](http://www.numpy.org/) and [Matplotlib](https://matplotlib.org/) libraries. \n",
    "\n",
    "***Hint:*** This part of the data science pipeline will test those skills you acquired in the pandas Foundations course, Module One. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aEau5nEvJpgm"
   },
   "source": [
    "#### 1.1. Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7Bt_Q_oPJpgn"
   },
   "outputs": [],
   "source": [
    "# Let's import the pandas, numpy libraries as pd, and np respectively. \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#print(pd.__version__)\n",
    "\n",
    "# Load the pyplot collection of functions from matplotlib, as plt \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "koUrawxsJpgq"
   },
   "source": [
    "#### 1.2.  Loading the data\n",
    "Your data comes from the [London Datastore](https://data.london.gov.uk/): a free, open-source data-sharing portal for London-oriented datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AiLiD4v3Jpgr"
   },
   "outputs": [],
   "source": [
    "# First, make a variable called url_LondonHousePrices, and assign it the following link, enclosed in quotation-marks as a string:\n",
    "# https://data.london.gov.uk/download/uk-house-price-index/70ac0766-8902-4eb5-aab5-01951aaed773/UK%20House%20price%20index.xls\n",
    "\n",
    "url_LondonHousePrices = \"https://data.london.gov.uk/download/uk-house-price-index/70ac0766-8902-4eb5-aab5-01951aaed773/UK%20House%20price%20index.xls\"\n",
    "\n",
    "# The dataset we're interested in contains the Average prices of the houses, and is actually on a particular sheet of the Excel file. \n",
    "# As a result, we need to specify the sheet name in the read_excel() method.\n",
    "# Put this data into a variable called properties.  \n",
    "properties = pd.read_excel(url_LondonHousePrices, sheet_name='Average price', index_col= None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "POukEJXgJpgu"
   },
   "source": [
    "### 2. Cleaning, transforming, and visualizing\n",
    "This second stage is arguably the most important part of any Data Science project. The first thing to do is take a proper look at the data. Cleaning forms the majority of this stage, and can be done both before or after Transformation.\n",
    "\n",
    "The end goal of data cleaning is to have tidy data. When data is tidy: \n",
    "\n",
    "1. Each variable has a column.\n",
    "2. Each observation forms a row.\n",
    "\n",
    "Keep the end goal in mind as you move through this process, every step will take you closer. \n",
    "\n",
    "\n",
    "\n",
    "***Hint:*** This part of the data science pipeline should test those skills you acquired in: \n",
    "- Intermediate Python for data science, all modules.\n",
    "- pandas Foundations, all modules. \n",
    "- Manipulating DataFrames with pandas, all modules.\n",
    "- Data Types for Data Science, Module Four.\n",
    "- Python Data Science Toolbox - Part One, all modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Te0Q548tnzZa"
   },
   "source": [
    "**2.1. Exploring your data** \n",
    "\n",
    "Think about your pandas functions for checking out a dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>City of London</th>\n",
       "      <th>Barking &amp; Dagenham</th>\n",
       "      <th>Barnet</th>\n",
       "      <th>Bexley</th>\n",
       "      <th>Brent</th>\n",
       "      <th>Bromley</th>\n",
       "      <th>Camden</th>\n",
       "      <th>Croydon</th>\n",
       "      <th>Ealing</th>\n",
       "      <th>...</th>\n",
       "      <th>NORTH WEST</th>\n",
       "      <th>YORKS &amp; THE HUMBER</th>\n",
       "      <th>EAST MIDLANDS</th>\n",
       "      <th>WEST MIDLANDS</th>\n",
       "      <th>EAST OF ENGLAND</th>\n",
       "      <th>LONDON</th>\n",
       "      <th>SOUTH EAST</th>\n",
       "      <th>SOUTH WEST</th>\n",
       "      <th>Unnamed: 47</th>\n",
       "      <th>England</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaT</td>\n",
       "      <td>E09000001</td>\n",
       "      <td>E09000002</td>\n",
       "      <td>E09000003</td>\n",
       "      <td>E09000004</td>\n",
       "      <td>E09000005</td>\n",
       "      <td>E09000006</td>\n",
       "      <td>E09000007</td>\n",
       "      <td>E09000008</td>\n",
       "      <td>E09000009</td>\n",
       "      <td>...</td>\n",
       "      <td>E12000002</td>\n",
       "      <td>E12000003</td>\n",
       "      <td>E12000004</td>\n",
       "      <td>E12000005</td>\n",
       "      <td>E12000006</td>\n",
       "      <td>E12000007</td>\n",
       "      <td>E12000008</td>\n",
       "      <td>E12000009</td>\n",
       "      <td>NaN</td>\n",
       "      <td>E92000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>91448.98487</td>\n",
       "      <td>50460.2266</td>\n",
       "      <td>93284.51832</td>\n",
       "      <td>64958.09036</td>\n",
       "      <td>71306.56698</td>\n",
       "      <td>81671.47692</td>\n",
       "      <td>120932.8881</td>\n",
       "      <td>69158.16225</td>\n",
       "      <td>79885.89069</td>\n",
       "      <td>...</td>\n",
       "      <td>43958.48001</td>\n",
       "      <td>44803.42878</td>\n",
       "      <td>45544.52227</td>\n",
       "      <td>48527.52339</td>\n",
       "      <td>56701.5961</td>\n",
       "      <td>74435.76052</td>\n",
       "      <td>64018.87894</td>\n",
       "      <td>54705.1579</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53202.77128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1995-02-01</td>\n",
       "      <td>82202.77314</td>\n",
       "      <td>51085.77983</td>\n",
       "      <td>93190.16963</td>\n",
       "      <td>64787.92069</td>\n",
       "      <td>72022.26197</td>\n",
       "      <td>81657.55944</td>\n",
       "      <td>119508.8622</td>\n",
       "      <td>68951.09542</td>\n",
       "      <td>80897.06551</td>\n",
       "      <td>...</td>\n",
       "      <td>43925.42289</td>\n",
       "      <td>44528.80721</td>\n",
       "      <td>46051.57066</td>\n",
       "      <td>49341.29029</td>\n",
       "      <td>56593.59475</td>\n",
       "      <td>72777.93709</td>\n",
       "      <td>63715.02399</td>\n",
       "      <td>54356.14843</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53096.1549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1995-03-01</td>\n",
       "      <td>79120.70256</td>\n",
       "      <td>51268.96956</td>\n",
       "      <td>92247.52435</td>\n",
       "      <td>64367.49344</td>\n",
       "      <td>72015.76274</td>\n",
       "      <td>81449.31143</td>\n",
       "      <td>120282.2131</td>\n",
       "      <td>68712.44341</td>\n",
       "      <td>81379.86288</td>\n",
       "      <td>...</td>\n",
       "      <td>44434.8681</td>\n",
       "      <td>45200.46775</td>\n",
       "      <td>45383.82395</td>\n",
       "      <td>49442.17973</td>\n",
       "      <td>56171.18278</td>\n",
       "      <td>73896.84204</td>\n",
       "      <td>64113.60858</td>\n",
       "      <td>53583.07667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53201.2843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1995-04-01</td>\n",
       "      <td>77101.20804</td>\n",
       "      <td>53133.50526</td>\n",
       "      <td>90762.87492</td>\n",
       "      <td>64277.66881</td>\n",
       "      <td>72965.63094</td>\n",
       "      <td>81124.41227</td>\n",
       "      <td>120097.899</td>\n",
       "      <td>68610.04641</td>\n",
       "      <td>82188.90498</td>\n",
       "      <td>...</td>\n",
       "      <td>44267.7796</td>\n",
       "      <td>45614.34341</td>\n",
       "      <td>46124.23045</td>\n",
       "      <td>49455.93299</td>\n",
       "      <td>56567.89582</td>\n",
       "      <td>74455.28754</td>\n",
       "      <td>64623.22395</td>\n",
       "      <td>54786.01938</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53590.8548</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0 City of London Barking & Dagenham       Barnet       Bexley  \\\n",
       "0        NaT      E09000001          E09000002    E09000003    E09000004   \n",
       "1 1995-01-01    91448.98487         50460.2266  93284.51832  64958.09036   \n",
       "2 1995-02-01    82202.77314        51085.77983  93190.16963  64787.92069   \n",
       "3 1995-03-01    79120.70256        51268.96956  92247.52435  64367.49344   \n",
       "4 1995-04-01    77101.20804        53133.50526  90762.87492  64277.66881   \n",
       "\n",
       "         Brent      Bromley       Camden      Croydon       Ealing  ...  \\\n",
       "0    E09000005    E09000006    E09000007    E09000008    E09000009  ...   \n",
       "1  71306.56698  81671.47692  120932.8881  69158.16225  79885.89069  ...   \n",
       "2  72022.26197  81657.55944  119508.8622  68951.09542  80897.06551  ...   \n",
       "3  72015.76274  81449.31143  120282.2131  68712.44341  81379.86288  ...   \n",
       "4  72965.63094  81124.41227   120097.899  68610.04641  82188.90498  ...   \n",
       "\n",
       "    NORTH WEST YORKS & THE HUMBER EAST MIDLANDS WEST MIDLANDS EAST OF ENGLAND  \\\n",
       "0    E12000002          E12000003     E12000004     E12000005       E12000006   \n",
       "1  43958.48001        44803.42878   45544.52227   48527.52339      56701.5961   \n",
       "2  43925.42289        44528.80721   46051.57066   49341.29029     56593.59475   \n",
       "3   44434.8681        45200.46775   45383.82395   49442.17973     56171.18278   \n",
       "4   44267.7796        45614.34341   46124.23045   49455.93299     56567.89582   \n",
       "\n",
       "        LONDON   SOUTH EAST   SOUTH WEST Unnamed: 47      England  \n",
       "0    E12000007    E12000008    E12000009         NaN    E92000001  \n",
       "1  74435.76052  64018.87894   54705.1579         NaN  53202.77128  \n",
       "2  72777.93709  63715.02399  54356.14843         NaN   53096.1549  \n",
       "3  73896.84204  64113.60858  53583.07667         NaN   53201.2843  \n",
       "4  74455.28754  64623.22395  54786.01938         NaN   53590.8548  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "properties.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'City of London', 'Barking & Dagenham', 'Barnet',\n",
       "       'Bexley', 'Brent', 'Bromley', 'Camden', 'Croydon', 'Ealing', 'Enfield',\n",
       "       'Greenwich', 'Hackney', 'Hammersmith & Fulham', 'Haringey', 'Harrow',\n",
       "       'Havering', 'Hillingdon', 'Hounslow', 'Islington',\n",
       "       'Kensington & Chelsea', 'Kingston upon Thames', 'Lambeth', 'Lewisham',\n",
       "       'Merton', 'Newham', 'Redbridge', 'Richmond upon Thames', 'Southwark',\n",
       "       'Sutton', 'Tower Hamlets', 'Waltham Forest', 'Wandsworth',\n",
       "       'Westminster', 'Unnamed: 34', 'Inner London', 'Outer London',\n",
       "       'Unnamed: 37', 'NORTH EAST', 'NORTH WEST', 'YORKS & THE HUMBER',\n",
       "       'EAST MIDLANDS', 'WEST MIDLANDS', 'EAST OF ENGLAND', 'LONDON',\n",
       "       'SOUTH EAST', 'SOUTH WEST', 'Unnamed: 47', 'England'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "properties.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0               True\n",
       "City of London          False\n",
       "Barking & Dagenham      False\n",
       "Barnet                  False\n",
       "Bexley                  False\n",
       "Brent                   False\n",
       "Bromley                 False\n",
       "Camden                  False\n",
       "Croydon                 False\n",
       "Ealing                  False\n",
       "Enfield                 False\n",
       "Greenwich               False\n",
       "Hackney                 False\n",
       "Hammersmith & Fulham    False\n",
       "Haringey                False\n",
       "Harrow                  False\n",
       "Havering                False\n",
       "Hillingdon              False\n",
       "Hounslow                False\n",
       "Islington               False\n",
       "Kensington & Chelsea    False\n",
       "Kingston upon Thames    False\n",
       "Lambeth                 False\n",
       "Lewisham                False\n",
       "Merton                  False\n",
       "Newham                  False\n",
       "Redbridge               False\n",
       "Richmond upon Thames    False\n",
       "Southwark               False\n",
       "Sutton                  False\n",
       "Tower Hamlets           False\n",
       "Waltham Forest          False\n",
       "Wandsworth              False\n",
       "Westminster             False\n",
       "Unnamed: 34              True\n",
       "Inner London            False\n",
       "Outer London            False\n",
       "Unnamed: 37              True\n",
       "NORTH EAST              False\n",
       "NORTH WEST              False\n",
       "YORKS & THE HUMBER      False\n",
       "EAST MIDLANDS           False\n",
       "WEST MIDLANDS           False\n",
       "EAST OF ENGLAND         False\n",
       "LONDON                  False\n",
       "SOUTH EAST              False\n",
       "SOUTH WEST              False\n",
       "Unnamed: 47              True\n",
       "England                 False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "properties.isna().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tE9Sqt9-oAta"
   },
   "source": [
    "**2.2. Cleaning the data**\n",
    "\n",
    "You might find you need to transpose your dataframe, check out what its row indexes are, and reset the index. You  also might find you need to assign the values of the first row to your column headings  . (Hint: recall the .columns feature of DataFrames, as well as the iloc[] method).\n",
    "\n",
    "Don't be afraid to use StackOverflow for help  with this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Rxirxw_qoAJa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0              1\n",
       "City of London          0\n",
       "Barking & Dagenham      0\n",
       "Barnet                  0\n",
       "Bexley                  0\n",
       "Brent                   0\n",
       "Bromley                 0\n",
       "Camden                  0\n",
       "Croydon                 0\n",
       "Ealing                  0\n",
       "Enfield                 0\n",
       "Greenwich               0\n",
       "Hackney                 0\n",
       "Hammersmith & Fulham    0\n",
       "Haringey                0\n",
       "Harrow                  0\n",
       "Havering                0\n",
       "Hillingdon              0\n",
       "Hounslow                0\n",
       "Islington               0\n",
       "Kensington & Chelsea    0\n",
       "Kingston upon Thames    0\n",
       "Lambeth                 0\n",
       "Lewisham                0\n",
       "Merton                  0\n",
       "Newham                  0\n",
       "Redbridge               0\n",
       "Richmond upon Thames    0\n",
       "Southwark               0\n",
       "Sutton                  0\n",
       "Tower Hamlets           0\n",
       "Waltham Forest          0\n",
       "Wandsworth              0\n",
       "Westminster             0\n",
       "Inner London            0\n",
       "Outer London            0\n",
       "NORTH EAST              0\n",
       "NORTH WEST              0\n",
       "YORKS & THE HUMBER      0\n",
       "EAST MIDLANDS           0\n",
       "WEST MIDLANDS           0\n",
       "EAST OF ENGLAND         0\n",
       "LONDON                  0\n",
       "SOUTH EAST              0\n",
       "SOUTH WEST              0\n",
       "England                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del properties[\"Unnamed: 34\"]\n",
    "del properties[\"Unnamed: 37\"]\n",
    "del properties[\"Unnamed: 47\"]\n",
    "properties.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>309</th>\n",
       "      <th>310</th>\n",
       "      <th>311</th>\n",
       "      <th>312</th>\n",
       "      <th>313</th>\n",
       "      <th>314</th>\n",
       "      <th>315</th>\n",
       "      <th>316</th>\n",
       "      <th>317</th>\n",
       "      <th>318</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <td>NaT</td>\n",
       "      <td>1995-01-01 00:00:00</td>\n",
       "      <td>1995-02-01 00:00:00</td>\n",
       "      <td>1995-03-01 00:00:00</td>\n",
       "      <td>1995-04-01 00:00:00</td>\n",
       "      <td>1995-05-01 00:00:00</td>\n",
       "      <td>1995-06-01 00:00:00</td>\n",
       "      <td>1995-07-01 00:00:00</td>\n",
       "      <td>1995-08-01 00:00:00</td>\n",
       "      <td>1995-09-01 00:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>2020-09-01 00:00:00</td>\n",
       "      <td>2020-10-01 00:00:00</td>\n",
       "      <td>2020-11-01 00:00:00</td>\n",
       "      <td>2020-12-01 00:00:00</td>\n",
       "      <td>2021-01-01 00:00:00</td>\n",
       "      <td>2021-02-01 00:00:00</td>\n",
       "      <td>2021-03-01 00:00:00</td>\n",
       "      <td>2021-04-01 00:00:00</td>\n",
       "      <td>2021-05-01 00:00:00</td>\n",
       "      <td>2021-06-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>City of London</th>\n",
       "      <td>E09000001</td>\n",
       "      <td>91448.98487</td>\n",
       "      <td>82202.77314</td>\n",
       "      <td>79120.70256</td>\n",
       "      <td>77101.20804</td>\n",
       "      <td>84409.14932</td>\n",
       "      <td>94900.51244</td>\n",
       "      <td>110128.0423</td>\n",
       "      <td>112329.4376</td>\n",
       "      <td>104473.1096</td>\n",
       "      <td>...</td>\n",
       "      <td>798499.1646</td>\n",
       "      <td>836807.0518</td>\n",
       "      <td>769391.7847</td>\n",
       "      <td>801999.0466</td>\n",
       "      <td>760383.824</td>\n",
       "      <td>730222.3496</td>\n",
       "      <td>726743.0772</td>\n",
       "      <td>739454.4285</td>\n",
       "      <td>767715.6627</td>\n",
       "      <td>756163.9647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Barking &amp; Dagenham</th>\n",
       "      <td>E09000002</td>\n",
       "      <td>50460.2266</td>\n",
       "      <td>51085.77983</td>\n",
       "      <td>51268.96956</td>\n",
       "      <td>53133.50526</td>\n",
       "      <td>53042.24852</td>\n",
       "      <td>53700.34831</td>\n",
       "      <td>52113.12157</td>\n",
       "      <td>52232.19868</td>\n",
       "      <td>51471.61353</td>\n",
       "      <td>...</td>\n",
       "      <td>301702.4656</td>\n",
       "      <td>304852.1338</td>\n",
       "      <td>305012.3291</td>\n",
       "      <td>309560.1023</td>\n",
       "      <td>311684.9905</td>\n",
       "      <td>315391.0211</td>\n",
       "      <td>314172.1341</td>\n",
       "      <td>313280.4834</td>\n",
       "      <td>310713.7151</td>\n",
       "      <td>319220.4702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Barnet</th>\n",
       "      <td>E09000003</td>\n",
       "      <td>93284.51832</td>\n",
       "      <td>93190.16963</td>\n",
       "      <td>92247.52435</td>\n",
       "      <td>90762.87492</td>\n",
       "      <td>90258.00033</td>\n",
       "      <td>90107.23471</td>\n",
       "      <td>91441.24768</td>\n",
       "      <td>92361.31512</td>\n",
       "      <td>93273.12245</td>\n",
       "      <td>...</td>\n",
       "      <td>533619.23</td>\n",
       "      <td>530353.5205</td>\n",
       "      <td>528816.4928</td>\n",
       "      <td>532528.0926</td>\n",
       "      <td>538413.261</td>\n",
       "      <td>538537.8796</td>\n",
       "      <td>542794.6969</td>\n",
       "      <td>538530.3551</td>\n",
       "      <td>540475.0074</td>\n",
       "      <td>548442.3483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bexley</th>\n",
       "      <td>E09000004</td>\n",
       "      <td>64958.09036</td>\n",
       "      <td>64787.92069</td>\n",
       "      <td>64367.49344</td>\n",
       "      <td>64277.66881</td>\n",
       "      <td>63997.13588</td>\n",
       "      <td>64252.32335</td>\n",
       "      <td>63722.70055</td>\n",
       "      <td>64432.60005</td>\n",
       "      <td>64509.54767</td>\n",
       "      <td>...</td>\n",
       "      <td>345061.4945</td>\n",
       "      <td>345404.9836</td>\n",
       "      <td>346252.9145</td>\n",
       "      <td>352260.8385</td>\n",
       "      <td>356024.477</td>\n",
       "      <td>359368.9877</td>\n",
       "      <td>362227.5335</td>\n",
       "      <td>364947.2557</td>\n",
       "      <td>364266.9832</td>\n",
       "      <td>364502.0488</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 319 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          0                    1                    2    \\\n",
       "Unnamed: 0                NaT  1995-01-01 00:00:00  1995-02-01 00:00:00   \n",
       "City of London      E09000001          91448.98487          82202.77314   \n",
       "Barking & Dagenham  E09000002           50460.2266          51085.77983   \n",
       "Barnet              E09000003          93284.51832          93190.16963   \n",
       "Bexley              E09000004          64958.09036          64787.92069   \n",
       "\n",
       "                                    3                    4    \\\n",
       "Unnamed: 0          1995-03-01 00:00:00  1995-04-01 00:00:00   \n",
       "City of London              79120.70256          77101.20804   \n",
       "Barking & Dagenham          51268.96956          53133.50526   \n",
       "Barnet                      92247.52435          90762.87492   \n",
       "Bexley                      64367.49344          64277.66881   \n",
       "\n",
       "                                    5                    6    \\\n",
       "Unnamed: 0          1995-05-01 00:00:00  1995-06-01 00:00:00   \n",
       "City of London              84409.14932          94900.51244   \n",
       "Barking & Dagenham          53042.24852          53700.34831   \n",
       "Barnet                      90258.00033          90107.23471   \n",
       "Bexley                      63997.13588          64252.32335   \n",
       "\n",
       "                                    7                    8    \\\n",
       "Unnamed: 0          1995-07-01 00:00:00  1995-08-01 00:00:00   \n",
       "City of London              110128.0423          112329.4376   \n",
       "Barking & Dagenham          52113.12157          52232.19868   \n",
       "Barnet                      91441.24768          92361.31512   \n",
       "Bexley                      63722.70055          64432.60005   \n",
       "\n",
       "                                    9    ...                  309  \\\n",
       "Unnamed: 0          1995-09-01 00:00:00  ...  2020-09-01 00:00:00   \n",
       "City of London              104473.1096  ...          798499.1646   \n",
       "Barking & Dagenham          51471.61353  ...          301702.4656   \n",
       "Barnet                      93273.12245  ...            533619.23   \n",
       "Bexley                      64509.54767  ...          345061.4945   \n",
       "\n",
       "                                    310                  311  \\\n",
       "Unnamed: 0          2020-10-01 00:00:00  2020-11-01 00:00:00   \n",
       "City of London              836807.0518          769391.7847   \n",
       "Barking & Dagenham          304852.1338          305012.3291   \n",
       "Barnet                      530353.5205          528816.4928   \n",
       "Bexley                      345404.9836          346252.9145   \n",
       "\n",
       "                                    312                  313  \\\n",
       "Unnamed: 0          2020-12-01 00:00:00  2021-01-01 00:00:00   \n",
       "City of London              801999.0466           760383.824   \n",
       "Barking & Dagenham          309560.1023          311684.9905   \n",
       "Barnet                      532528.0926           538413.261   \n",
       "Bexley                      352260.8385           356024.477   \n",
       "\n",
       "                                    314                  315  \\\n",
       "Unnamed: 0          2021-02-01 00:00:00  2021-03-01 00:00:00   \n",
       "City of London              730222.3496          726743.0772   \n",
       "Barking & Dagenham          315391.0211          314172.1341   \n",
       "Barnet                      538537.8796          542794.6969   \n",
       "Bexley                      359368.9877          362227.5335   \n",
       "\n",
       "                                    316                  317  \\\n",
       "Unnamed: 0          2021-04-01 00:00:00  2021-05-01 00:00:00   \n",
       "City of London              739454.4285          767715.6627   \n",
       "Barking & Dagenham          313280.4834          310713.7151   \n",
       "Barnet                      538530.3551          540475.0074   \n",
       "Bexley                      364947.2557          364266.9832   \n",
       "\n",
       "                                    318  \n",
       "Unnamed: 0          2021-06-01 00:00:00  \n",
       "City of London              756163.9647  \n",
       "Barking & Dagenham          319220.4702  \n",
       "Barnet                      548442.3483  \n",
       "Bexley                      364502.0488  \n",
       "\n",
       "[5 rows x 319 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "properties= properties.transpose()\n",
    "#properties.isna().sum()\n",
    "properties.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "properties = properties.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=46, step=1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "properties.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o1uLbJAsoIjK"
   },
   "source": [
    "**2.3. Cleaning the data (part 2)**\n",
    "\n",
    "You might we have to **rename** a couple columns. How do you do this? The clue's pretty bold..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GKkmn1AnoVZS"
   },
   "outputs": [],
   "source": [
    "properties= properties.rename(columns= { 'index':'London_Borough',pd.NaT:'ID'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>London_Borough</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>309</th>\n",
       "      <th>310</th>\n",
       "      <th>311</th>\n",
       "      <th>312</th>\n",
       "      <th>313</th>\n",
       "      <th>314</th>\n",
       "      <th>315</th>\n",
       "      <th>316</th>\n",
       "      <th>317</th>\n",
       "      <th>318</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Unnamed: 0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1995-01-01 00:00:00</td>\n",
       "      <td>1995-02-01 00:00:00</td>\n",
       "      <td>1995-03-01 00:00:00</td>\n",
       "      <td>1995-04-01 00:00:00</td>\n",
       "      <td>1995-05-01 00:00:00</td>\n",
       "      <td>1995-06-01 00:00:00</td>\n",
       "      <td>1995-07-01 00:00:00</td>\n",
       "      <td>1995-08-01 00:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>2020-09-01 00:00:00</td>\n",
       "      <td>2020-10-01 00:00:00</td>\n",
       "      <td>2020-11-01 00:00:00</td>\n",
       "      <td>2020-12-01 00:00:00</td>\n",
       "      <td>2021-01-01 00:00:00</td>\n",
       "      <td>2021-02-01 00:00:00</td>\n",
       "      <td>2021-03-01 00:00:00</td>\n",
       "      <td>2021-04-01 00:00:00</td>\n",
       "      <td>2021-05-01 00:00:00</td>\n",
       "      <td>2021-06-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>City of London</td>\n",
       "      <td>E09000001</td>\n",
       "      <td>91448.98487</td>\n",
       "      <td>82202.77314</td>\n",
       "      <td>79120.70256</td>\n",
       "      <td>77101.20804</td>\n",
       "      <td>84409.14932</td>\n",
       "      <td>94900.51244</td>\n",
       "      <td>110128.0423</td>\n",
       "      <td>112329.4376</td>\n",
       "      <td>...</td>\n",
       "      <td>798499.1646</td>\n",
       "      <td>836807.0518</td>\n",
       "      <td>769391.7847</td>\n",
       "      <td>801999.0466</td>\n",
       "      <td>760383.824</td>\n",
       "      <td>730222.3496</td>\n",
       "      <td>726743.0772</td>\n",
       "      <td>739454.4285</td>\n",
       "      <td>767715.6627</td>\n",
       "      <td>756163.9647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Barking &amp; Dagenham</td>\n",
       "      <td>E09000002</td>\n",
       "      <td>50460.2266</td>\n",
       "      <td>51085.77983</td>\n",
       "      <td>51268.96956</td>\n",
       "      <td>53133.50526</td>\n",
       "      <td>53042.24852</td>\n",
       "      <td>53700.34831</td>\n",
       "      <td>52113.12157</td>\n",
       "      <td>52232.19868</td>\n",
       "      <td>...</td>\n",
       "      <td>301702.4656</td>\n",
       "      <td>304852.1338</td>\n",
       "      <td>305012.3291</td>\n",
       "      <td>309560.1023</td>\n",
       "      <td>311684.9905</td>\n",
       "      <td>315391.0211</td>\n",
       "      <td>314172.1341</td>\n",
       "      <td>313280.4834</td>\n",
       "      <td>310713.7151</td>\n",
       "      <td>319220.4702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Barnet</td>\n",
       "      <td>E09000003</td>\n",
       "      <td>93284.51832</td>\n",
       "      <td>93190.16963</td>\n",
       "      <td>92247.52435</td>\n",
       "      <td>90762.87492</td>\n",
       "      <td>90258.00033</td>\n",
       "      <td>90107.23471</td>\n",
       "      <td>91441.24768</td>\n",
       "      <td>92361.31512</td>\n",
       "      <td>...</td>\n",
       "      <td>533619.23</td>\n",
       "      <td>530353.5205</td>\n",
       "      <td>528816.4928</td>\n",
       "      <td>532528.0926</td>\n",
       "      <td>538413.261</td>\n",
       "      <td>538537.8796</td>\n",
       "      <td>542794.6969</td>\n",
       "      <td>538530.3551</td>\n",
       "      <td>540475.0074</td>\n",
       "      <td>548442.3483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bexley</td>\n",
       "      <td>E09000004</td>\n",
       "      <td>64958.09036</td>\n",
       "      <td>64787.92069</td>\n",
       "      <td>64367.49344</td>\n",
       "      <td>64277.66881</td>\n",
       "      <td>63997.13588</td>\n",
       "      <td>64252.32335</td>\n",
       "      <td>63722.70055</td>\n",
       "      <td>64432.60005</td>\n",
       "      <td>...</td>\n",
       "      <td>345061.4945</td>\n",
       "      <td>345404.9836</td>\n",
       "      <td>346252.9145</td>\n",
       "      <td>352260.8385</td>\n",
       "      <td>356024.477</td>\n",
       "      <td>359368.9877</td>\n",
       "      <td>362227.5335</td>\n",
       "      <td>364947.2557</td>\n",
       "      <td>364266.9832</td>\n",
       "      <td>364502.0488</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 320 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       London_Borough          0                    1                    2  \\\n",
       "0          Unnamed: 0        NaT  1995-01-01 00:00:00  1995-02-01 00:00:00   \n",
       "1      City of London  E09000001          91448.98487          82202.77314   \n",
       "2  Barking & Dagenham  E09000002           50460.2266          51085.77983   \n",
       "3              Barnet  E09000003          93284.51832          93190.16963   \n",
       "4              Bexley  E09000004          64958.09036          64787.92069   \n",
       "\n",
       "                     3                    4                    5  \\\n",
       "0  1995-03-01 00:00:00  1995-04-01 00:00:00  1995-05-01 00:00:00   \n",
       "1          79120.70256          77101.20804          84409.14932   \n",
       "2          51268.96956          53133.50526          53042.24852   \n",
       "3          92247.52435          90762.87492          90258.00033   \n",
       "4          64367.49344          64277.66881          63997.13588   \n",
       "\n",
       "                     6                    7                    8  ...  \\\n",
       "0  1995-06-01 00:00:00  1995-07-01 00:00:00  1995-08-01 00:00:00  ...   \n",
       "1          94900.51244          110128.0423          112329.4376  ...   \n",
       "2          53700.34831          52113.12157          52232.19868  ...   \n",
       "3          90107.23471          91441.24768          92361.31512  ...   \n",
       "4          64252.32335          63722.70055          64432.60005  ...   \n",
       "\n",
       "                   309                  310                  311  \\\n",
       "0  2020-09-01 00:00:00  2020-10-01 00:00:00  2020-11-01 00:00:00   \n",
       "1          798499.1646          836807.0518          769391.7847   \n",
       "2          301702.4656          304852.1338          305012.3291   \n",
       "3            533619.23          530353.5205          528816.4928   \n",
       "4          345061.4945          345404.9836          346252.9145   \n",
       "\n",
       "                   312                  313                  314  \\\n",
       "0  2020-12-01 00:00:00  2021-01-01 00:00:00  2021-02-01 00:00:00   \n",
       "1          801999.0466           760383.824          730222.3496   \n",
       "2          309560.1023          311684.9905          315391.0211   \n",
       "3          532528.0926           538413.261          538537.8796   \n",
       "4          352260.8385           356024.477          359368.9877   \n",
       "\n",
       "                   315                  316                  317  \\\n",
       "0  2021-03-01 00:00:00  2021-04-01 00:00:00  2021-05-01 00:00:00   \n",
       "1          726743.0772          739454.4285          767715.6627   \n",
       "2          314172.1341          313280.4834          310713.7151   \n",
       "3          542794.6969          538530.3551          540475.0074   \n",
       "4          362227.5335          364947.2557          364266.9832   \n",
       "\n",
       "                   318  \n",
       "0  2021-06-01 00:00:00  \n",
       "1          756163.9647  \n",
       "2          319220.4702  \n",
       "3          548442.3483  \n",
       "4          364502.0488  \n",
       "\n",
       "[5 rows x 320 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "properties.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jy8BzXHmoWEw"
   },
   "source": [
    "**2.4.Transforming the data**\n",
    "\n",
    "Remember what Wes McKinney said about tidy data? \n",
    "\n",
    "You might need to **melt** your DataFrame here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S2wM0qLuo2Zt"
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"The following 'id_vars' are not present in the DataFrame: ['ID']\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-ed7b60ccf2f2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mclean_properties\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmelt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mproperties\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mid_vars\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'London_Borough'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ID'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\melt.py\u001b[0m in \u001b[0;36mmelt\u001b[1;34m(frame, id_vars, value_vars, var_name, value_name, col_level, ignore_index)\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[0mmissing\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mIndex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mid_vars\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdifference\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcols\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mmissing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m                 raise KeyError(\n\u001b[0m\u001b[0;32m     65\u001b[0m                     \u001b[1;34m\"The following 'id_vars' are not present \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m                     \u001b[1;34mf\"in the DataFrame: {list(missing)}\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"The following 'id_vars' are not present in the DataFrame: ['ID']\""
     ]
    }
   ],
   "source": [
    "clean_properties = pd.melt(properties, id_vars= ['London_Borough', 'ID'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7kIsgAo7o3mf"
   },
   "source": [
    "Remember to make sure your column data types are all correct. Average prices, for example, should be floating point numbers... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#properties.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZcR4IHbcpOaq"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clean_properties' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-a75b62af8ba9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mclean_properties\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'clean_properties' is not defined"
     ]
    }
   ],
   "source": [
    "clean_properties.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#renaming variable and value columns names\n",
    "clean_properties = clean_properties.rename(columns = {'variable': 'Month','value': \"Avg_price\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_properties.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean_properties.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_properties['Avg_price']=pd.to_numeric(clean_properties['Avg_price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean_properties.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean_properties.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "knLUXHLypOtw"
   },
   "source": [
    "**2.5. Cleaning the data (part 3)**\n",
    "\n",
    "Do we have an equal number of observations in the ID, Average Price, Month, and London Borough columns? Remember that there are only 32 London Boroughs. How many entries do you have in that column? \n",
    "\n",
    "Check out the contents of the London Borough column, and if you find null values, get rid of them however you see fit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BnvTW5a3p0fC"
   },
   "outputs": [],
   "source": [
    "clean_properties.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean_properties[\"London_Borough\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filltering and getting rid of all data that is not concerning the 32  boroughs of London  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a list of non-Boroughs\n",
    "non_Boroughs_list = ['Inner London', 'Outer London', \n",
    "               'NORTH EAST', 'NORTH WEST', 'YORKS & THE HUMBER', \n",
    "               'EAST MIDLANDS', 'WEST MIDLANDS',\n",
    "              'EAST OF ENGLAND', 'LONDON', 'SOUTH EAST', \n",
    "              'SOUTH WEST', 'England']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter rows values for Boroughs_properties that are NOT in the nonBoroughs list.\n",
    "Boroughs_properties = clean_properties[~clean_properties.London_Borough.isin(non_Boroughs_list)]\n",
    "#Boroughs_properties.London_Borough.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the clean dataFrame to: df\n",
    "df = Boroughs_properties\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filltering and getting rid of all observation rows that are not between 1998 and 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are interested in data over the period of TWO DECADES back: 1998-2018 \n",
    "\n",
    "temp_df = df.set_index(\"Month\").sort_index()\n",
    "df_temp = temp_df.loc[\"1998-01-01\":\"2018-01-01\"]\n",
    "\n",
    "#reset index back to range index\n",
    "df_temp = df_temp.reset_index()\n",
    "\n",
    "#df_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "TO Dipanjan: \n",
    "\n",
    "Question 1 - what happend to column Avg_price?\n",
    "why the format of the float has changed, to 1 dot aftaer the first number?,\n",
    "and whats the best way to deal with it?\n",
    "\"\"\"\n",
    "#check out: scientific notation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return to original df column order and set back to : df\n",
    "df = df_temp[[\"London_Borough\",\"ID\",\"Month\",\"Avg_price\"]]\n",
    "#df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PGEx6mJsp6dG"
   },
   "source": [
    "**2.6. Visualizing the data**\n",
    "\n",
    "To visualize the data, why not subset on a particular London Borough? Maybe do a line plot of Month against Average Price?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ** More plots are shown in the Modeling section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nAg5pT9cqHAR"
   },
   "outputs": [],
   "source": [
    "df[df[\"London_Borough\"]=='Hackney'].plot(x=\"Month\",y=\"Avg_price\", kind=\"line\")\n",
    "plt.title(\"Hackney's properties average price over 1998-2018\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.lineplot(data=df, x=\"Month\", y=\"Avg_price\", hue=\"London_Borough\",legend= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aWTPqSJeqHnC"
   },
   "source": [
    "To limit the number of data points you have, you might want to extract the year from every month value your *Month* column. \n",
    "\n",
    "To this end, you *could* apply a ***lambda function***. Your logic could work as follows:\n",
    "1. look through the `Month` column\n",
    "2. extract the year from each individual value in that column \n",
    "3. store that corresponding year as separate column. \n",
    "\n",
    "Whether you go ahead with this is up to you. Just so long as you answer our initial brief: which boroughs of London have seen the greatest house price increase, on average, over the past two decades? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Limiting the number of data points we have, by extracting the year from every month value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e0DF92cyqnu8"
   },
   "outputs": [],
   "source": [
    "df[\"Year\"] = df[\"Month\"].apply(lambda m : m.year) \n",
    "#df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grouping-by Borough and year "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-b43dd78ac25f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mborough_yearly_mean\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"London_Borough\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"Year\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Avg_price\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m#borough_yearly_mean\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#returning it to DataFrame view: dfg,  by reseting the index\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdfg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mborough_yearly_mean\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "borough_yearly_mean = df.groupby([\"London_Borough\",\"Year\"])[\"Avg_price\"].mean()\n",
    "#borough_yearly_mean\n",
    "\n",
    "#returning it to DataFrame view: dfg,  by reseting the index\n",
    "dfg = borough_yearly_mean.reset_index()\n",
    "#dfg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2knuTxAEqoJ4"
   },
   "source": [
    "**3. Modeling**\n",
    "\n",
    "Consider creating a function that will calculate a ratio of house prices, comparing the price of a house in 2018 to the price in 1998.\n",
    "\n",
    "Consider calling this function create_price_ratio.\n",
    "\n",
    "You'd want this function to:\n",
    "1. Take a filter of dfg, specifically where this filter constrains the London_Borough, as an argument. For example, one admissible argument should be: dfg[dfg['London_Borough']=='Camden'].\n",
    "2. Get the Average Price for that Borough, for the years 1998 and 2018.\n",
    "4. Calculate the ratio of the Average Price for 1998 divided by the Average Price for 2018.\n",
    "5. Return that ratio.\n",
    "\n",
    "Once you've written this function, you ultimately want to use it to iterate through all the unique London_Boroughs and work out the ratio capturing the difference of house prices between 1998 and 2018.\n",
    "\n",
    "Bear in mind: you don't have to write a function like this if you don't want to. If you can solve the brief otherwise, then great! \n",
    "\n",
    "***Hint***: This section should test the skills you acquired in:\n",
    "- Python Data Science Toolbox - Part One, all modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dfg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-957c19b4b3e2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# creating Boroughs names list: list_of_boroughs (contains 'City of London')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mdfg_temp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdfg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"London_Borough\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m#sort out only unique borough names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dfg' is not defined"
     ]
    }
   ],
   "source": [
    "# Sorting out unique boroughs names list: list_of_boroughs\n",
    "\n",
    "# creating Boroughs names list: list_of_boroughs (contains 'City of London')\n",
    "dfg_temp = dfg.set_index(\"London_Borough\")\n",
    "\n",
    "#sort out only unique borough names\n",
    "list_of_boroughs = list(dfg_temp.index.unique())\n",
    "#list_of_boroughs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a function that calculates a ratio of house prices for each borough, comparing the average price of a house in 2018 to the price in 1998"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_price_ratio(f_df, from_year, to_year):\n",
    "    ratios = list()\n",
    "    for borough in list_of_boroughs:\n",
    "        avg_price_from_year = f_df[(f_df['London_Borough']==borough) & (f_df['Year'] == from_year)].Avg_price\n",
    "        avg_price_up_to_year = f_df[(f_df['London_Borough']==borough) & (f_df['Year'] == to_year)].Avg_price\n",
    "        ratios.append(float(avg_price_from_year)/float(avg_price_up_to_year))\n",
    "    #print(type(ratios))\n",
    "    borough_ratios = list(zip(list_of_boroughs,ratios))\n",
    "    return borough_ratios\n",
    "\n",
    "#create_price_ratio(dfg, 2018,1998)\n",
    "#type(create_price_ratio(dfg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer to: \n",
    "### Which borough had the greatest increase in housing prices, on average, over the last two decades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dfg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-7422a76f1964>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcreate_price_ratio\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdfg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2018\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1998\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mitem\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mitem\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'dfg' is not defined"
     ]
    }
   ],
   "source": [
    "max(create_price_ratio(dfg,2018,1998), key=lambda item: item[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which boroughs of London have seen the greatest increase in housing prices, on average, over the last two decades?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataFrame sorted by greatest increase in descending order\n",
    "Sorted_by_AvgPriceRatio = sorted(create_price_ratio(dfg,2018,1998), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# present each borough with it's ratio in DataFrame look: \n",
    "bor_list=list()\n",
    "rat_list=list()\n",
    "\n",
    "#separating boroughs and ratios in seperate lists\n",
    "for item in Sorted_by_AvgPriceRatio:\n",
    "    bor,rat = item\n",
    "    bor_list.append(bor)\n",
    "    rat_list.append(rat)\n",
    "\n",
    "#create dictionary with borough and ratios as keys\n",
    "bor_dict = {'London_Borough':bor_list, 'Price_Ratio':rat_list }\n",
    "#import dictionary to a DataFrame for better presentation\n",
    "df_ratios = pd.DataFrame(bor_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function that creates top X boroughs plot lines over 1998-2018 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topX_line_plot(dataFrame,top_num):\n",
    "    topX = dataFrame.head(top_num)\n",
    "    lbX= list(topX.London_Borough)\n",
    "    dfX = df[df.London_Borough.isin(lbX)]\n",
    "    \n",
    "    return sns.lineplot(data=dfX, x=\"Month\", y=\"Avg_price\", hue=\"London_Borough\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Presenting:\n",
    "### All boroughs in descending order: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show plot line for All 33 boroughs\n",
    "topX_line_plot(df_ratios,33)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Presenting:\n",
    "### TOP 5 boroughs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topX_line_plot(df_ratios,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Presenting:\n",
    "### TOP 3 boroughs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topX_line_plot(df_ratios,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Presenting:\n",
    "### TOP borough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topX_line_plot(df_ratios,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NzYUI7FxJpgv"
   },
   "source": [
    "### 4. Conclusion\n",
    "What can you conclude? Type out your conclusion below. \n",
    "\n",
    "Look back at your notebook. Think about how you might summarize what you have done, and prepare a quick presentation on it to your mentor at your next meeting. \n",
    "\n",
    "We hope you enjoyed this practical project. It should have consolidated your data hygiene and pandas skills by looking at a real-world problem involving just the kind of dataset you might encounter as a budding data scientist. Congratulations, and looking forward to seeing you at the next step in the course! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Insight 1\n",
    "The borough that had the greatest increase in housing prices, on average, between 1998 and 2008 is Hackney borough."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Insight 2\n",
    "The top 10 boroughs that have seen on average the greatest increase in housing prices between1998 and 2008 are: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratios.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Insight 3 \n",
    "The boroughs that have seen on average the greatest increase in housing prices are not necessarily the most expensive boroughs, as we can see by 'Insight 2’ and the next figure plot: showing plot line for top 10 boroughs with average price increase over 1998-2018."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topX_line_plot(df_ratios,10)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Springboard Data Science Career Track Unit 4 Challenge - Tier 3 Complete .ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
